Appendix 1: Anomaly Recognition (AMLR) model steps
Amount Recognition
The AML hierarchy identifies data points, events, and/or observations that deviate from a dataset‚Äôs normal behavior, leading to money laundering, network frauds etc. The framework's initial step is to recognize the amount type feature for unusual pattern acknowledgment. The transaction behavior can be gathered due to the account activity regardless of other contexts, such as the customer cashed out $2000 in the morning and then again $3000 performed the transfer in the evening, remark as anomalous activity. We design a novel interpretable LSTM (Long short-term memory) to analyze the amount as a precious feature to recognize anomalies. Data from financial organizations are stacked as the input V of amount recognition, as shown in Figure.
As displayed in Figure 6, the design of the LSTM network incorporates memory blocks (cells) with a few states and gates. The cell state is the significant chain of information flow. It permits the information to stream forward unaltered. The neglect gate (ft) determines what information should be eliminated or kept. Information from the earlier hidden state (Dt-1) is passed through the sigmoid function and data from the current input (xt). The sigmoid function (r) determines values somewhere in between 0 & 1; assuming the worth is closer to 0, that is intended to forget, and in the ve that the worth is closer to 1 means to keep. Additionally, cell state vector Ct-1 control which elements will neglect. The below equation clarifies how the forget gate is determined:
ft = œÉ (Wr . [Dt-1, xt] + bf)
Where bf and Wf denote the biases and input weights matrices of forget gate (ft). The input gate (It) determines which data is important to add from the current input (xt) and furthermore to update cell state. This gate utilized the tanh function (Nt) to pass the current input and the hidden state to make values between -1 and 1 to assist direct the network. Moreover, to create a new memory, it is then applied to the old cell-stated (Ct-1) memory at time t-1, which produces new cell-stated (Ct) at time t as in Equations.
It = œÉ (Wi . [Dt-1, xt] + bi)
Nt = tanh (Wn . [Dt-1, xt] + + bn)
Ct = Ct-1 * ft + Nt  * It
Where b and W indicate the biases and input weights matrices of the input gate (ft). The output gate (Ot) respectively determines the output of the next hidden state (Dt) through the output of the sigmoid gate and with new values generated by tanh from cell state as in Equations.
Ot = œÉ (Wo . [Dt-1, xt] + bo)
Dt   = Ot tanh (Ct)
Where b and W denote the biases and input weights matrices of the output gate (ft). 
Figure 6: LSTM cell structure
Table 7: LSTM parameters and performance measures
LSTM Parameters	Description
Optimizer	The parameter that works to improve the performance. It has different types such as Adam, RMSprop, Adagrad etc.
Metric	Measure the performance such as accuracy etc.
Batch size	Refers to the number of windows of data we are passing at once.
Epochs	Refers to the number of iterations (forward and back-propagation) model necessities to make.

Transaction Type Recognition
Unlike extant transaction type recognition models such as DL that directly characterize raw data into transaction types in customers‚Äô transactions, we influence the amount recognition and recognize transaction type with a heuristic approach. LSTM yields the true value in transaction type recognition and its probability pn for every transaction type data segment. We propose a heuristic-based four-step process for the transaction type recognition in our framework to aggregate and recognize the most salient unusual transaction type from the transaction dataset.
Anomaly detection is done by involving the prediction errors as anomaly indicators. The prediction error contrasts the prediction made at time t ‚àí 1 and the input value received at time t. The prediction errors from training data are displayed using a Gaussian distribution. The parameters of the Gaussian, mean and variance, are computed using maximum likelihood estimation (MLE). On data, the log probability densities (PDs) of errors are calculated and utilized as anomaly scores: with lower values showing a more prominent probability of the perception being an anomaly. A validation set containing both ordinary data and anomalies is utilized to set a threshold on log PD values that can isolate anomalies from normal observations and incur as few false positives as could be expected. A separate test set is utilized to evaluate the model.
Time Recognition
The LSTM RNN is trained on high-dimensional data to learn normal time series patterns and optimize prediction accuracy. For this purpose, each dataset is divided into four subsets: a training set, N, with only normal values; validation set, VN, with only normal values; a second validation set, VA, with normal values and anomalies; and a test set, T, having both typical values and anomalies. The algorithm proceeds as follows:
1.	Set N is utilized for training the prediction model. We used Bayesian enhancement to find the best values for hyper-parameters: lookback, dropout, learning rate, and the organization architecture (number of hidden layers and units in each layer) (Snoel et al., 2012). We utilize a lookahead of more than 1, provided that the prediction accuracy is still reasonable. If predicting numerous time steps is not required and one necessity the best prediction accuracy, lookahead can be set to 1.
2.	N is utilized for early stopping to keep the model from overfitting the training data.
3.	Prediction errors on N are displayed utilizing Gaussian dissemination. The mean and variance of the circulation are assessed utilizing MLE.
4.	The trained prediction model is applied to VA. The appropriation parameters determined in the previous step are utilized to process the log PDs of the errors from VA. A threshold is set on the log PD values, isolating the anomalies, with barely any false problems expected.
5.	The set threshold is assessed utilizing the prediction errors from the test set T.
There was a modification required for the actual experiments. As per step 1 above, we train the model and streamline for prediction accuracy on set N. As per our suspicion, the model learns the normal time-series behavior and should have higher prediction errors on sets VA, and T, thereby permitting us to do anomaly detection.
Location Recognition
Since location recognition is defined as points whose locations are not typical of the patterns of the rest of the points in the dataset. The location recognition stage adopts an LSTM autoencoder to analyze unusual patterns and assign CO-AML labels for each indication in the data sequence. The encoder network takes the location sequence ùëã = [ùë•1, ùë•2, ‚ãØ , ùë•ùëõ ] as info, where each ùë•ùë° is an allocation label and the amount of activity as ùë°.
The LSTM autoencoder data process the entire location sequence and learn to concentrate and store the most salient short-term and long-term temporal unusual patterns in the hidden states. The final state is encoded as the semantics vector generating gates CO-AML labels for ùëã (Zhu et al. 2018). Vector s is repeated as the input for all n decoding time steps. The decoders‚Äô data extricate data from various dimensions of s for each time step.
Table 8: Summary of the proposed Hierarchical AMLR framework
Stage	Task	Model	Input	Result	Example
1	Amount recognition	LSTM +Autoencoder	Amount activity 	GL-AML	The withdrawn amount exceeds the limits 
2	Transaction type recognition	LSTM +Autoencoder	The sequence of transaction type activity	CO-AML	Cash-out, purchase, transfer
3	Time recognition	TIME SERIES LSTM	Time sequence of transaction	CL-AML	Transaction activity odd time
4	Location recognition	LSTM +Autoencoder	The sequence of the location of the transaction 	CO-AML	Transaction activity in another country
Extricated data is transferred by a common fully decoded layer to a lower dimension that matches the quantity of AML labels for classification; RElu function selects as the activation learning rate the most probable predefined label as the result ùë¶ùë° for time t. Through this progressive, multiphase AMLR framework, amount, transaction type, time, and location are naturally perceived from customers‚Äô transactions data. 
Experiment Design and Performance Metrics
We utilized all testbeds to conduct four sets of assessments: amount recognition, trans-type recognition, time recognition, and location recognition. Each corresponds to one stage in our proposed framework. Table 6 provides a full synopsis of the analyses. Experiment 1 evaluates amount recognition performance from customers' transactions. We used the 194634 instances for this experiment for classical deep learning benchmarks. We evaluated the proposed LSTM and autoencoder model against KNN, SVM (Heryadi et al., 2017), and standard performance metrics of precision, recall, and F1 score.
Experiment 1 - The LSTM RNN utilized had a lookback of 24, a lookahead of 12, two secret recurrent layers with 80 and 20 LSTM units individually, a dense output layer with 12 neurons, and a dropout of 0.1. We trained the prediction model with Adam optimizer utilizing a learning rate of .05, a decay of 0.99, and a batch size of 1024. The training was completed for 200 epochs with early halting. As the data doesn't contain any repeating patterns, we didn't maintain the LSTM state between batches. This model gave an MSE of 0.09 on N. Utilizing set VA an edge of ‚àí11 was set on the log PD values. The threshold was then assessed utilizing set T.
Experiment 2 - The RNN involved a solitary recurrent layer with 300 LSTM units, trailed by a dense output layer with 1 neuron and a dropout of 0.2. Lookback and lookahead were equivalent to 1. We trained the RNN for 50 epochs with early stopping and utilized Adam Optimizer with a learning rate of .01, decay of 0.99, and a group size of 672. Since the data has long cycles, we kept up with the LSTM state between batches. The outcomes on sets VA and T are displayed in figures 4.4 and 4.5 individually. The prediction model gave an MSE of .08 on N. A threshold of ‚àí24 was set utilizing the prediction blunders on VA.
Experiment 3 - The prediction model utilized was a stacked RNN comprising two hidden recurrent layers with 60 and 30 LSTM units individually, a dense output layer with 5 neurons, a lookback of 8, a lookahead of 5, and a dropout of 0.1. LSTM state was not maintained between batches. We trained the RNN utilizing Adam optimizer with a learning rate of 0.1, a decay of 0.99, and a batch size of 256. The model was trained for 50 epochs with early stopping. The MSE on set N was 0.10, and a threshold of 23 was set on the log PD values of prediction errors from set T.

